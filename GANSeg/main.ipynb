{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Information\n",
    "Name: GANSeg: Learning to Segment by Unsupervised Hierarchical Image Generation\n",
    "Link: https://arxiv.org/pdf/2112.01036.pdf\n",
    "    \n",
    "# Authors of Code\n",
    "Ahmet Kağan Kaya - 2598555 - \"kagan.kaya@metu.edu.tr\"\n",
    "\n",
    "# Paper Summary\n",
    "This paper proposes a GAN-based approach that generates images conditioned on latent masks, thereby alleviating full or weak annotations required by previous approaches. Part and background appearances are controlled by latent space and image generation is done by using both Point and Background Generator. Without requiring supervision of masks or points, this strategy increases robustness of mask to viewpoint and object position changes. It also lets us generate image-mask pairs for training a segmentation network, which outperforms state-of-the-art unsupervised segmentation methods on established benchmark.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"./figures/archi.png\" width=\"700\"/>\n",
    "<figcaption>Overall Architecture with 3 Different Levels</figcaption>\n",
    "</div>\n",
    "\n",
    "# Method\n",
    "## Level 1: Point Generation and Part Scale\n",
    "In the first level, independent noise vectors are used to generate the locations and appearances of $K$ parts. It is found that training can be stabilized by first predicting $n_{per} × K$ points. The part location and scale are computed from the mean and standard deviation of the corresponding $n_{per}$ points, which also regularizes training.\n",
    "\n",
    "$$ x_k = \\frac{1}{n_\\text{per}}\\sum_{i=1}^{n_\\text{per}} x_k^i, \\quad \\sigma_k = \\frac{\\sqrt{\\sum_i^{n_\\text{per}}\\|x_k^i- x_k\\|^2}}{n_\\text{per}-1}$$ \n",
    "$$ \\text{with }\\{x_k^{1}, ...,x_k^{n_\\text{per}}\\}_{k=1}^K = \\text{MLP}_\\text{point}(z_\\text{point}) $$ \n",
    "\n",
    "Again 3-layer multi-layer perceptron (MLP) is used to map $z_\\text{point}$ to $n_\\text{per}\\times K$ points $\\{x_k^{1}, ...,x_k^{n_\\text{per}}\\}_{k=1}^K$. \n",
    "Then part locations are calculated in terms of $\\{x_1,...,x_K\\}$ and part scales $\\{\\sigma_1,...,\\sigma_K\\}$\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"./figures/level1.png\" width=\"700\"/>\n",
    "<figcaption>Strategy for Level 1</figcaption>\n",
    "</div>\n",
    "\n",
    "## Level 2: From Points to Masks\n",
    "In the second level, Gaussian heatmaps are use to create masks for each image and model is used to generate the local independence and positional encoding  masks relative to the predicted part location. Gaussian heatmaps are generated for each part using the mean and standard deviation of each part defined in Level 1. The embedding $w_k$ is then multiplied with every pixel of the corresponding heatmap, generating a spatially localized embedding map. All $K$ part-specific embeddings are summed to form a single feature map $W_\\text{mask}\\in\\R^{D_\\text{emb}\\times H\\times W}$.\n",
    "$$ H_k(p)=\\exp\\left(-\\|p- x_k\\|_2^2 / \\sigma_k^2\\right) $$\n",
    "$$ W_\\text{mask}(p) = \\sum_{k=1}^K H_k(p)w_k. $$\n",
    "\n",
    "Generated embedding map $W_\\text{mask}$ will subsequently be used to generate masks, together with the mask starting tensor $M^{(0)}\\in\\R^{D_\\text{emb}\\times H\\times W}$. However, instead of using constant tensor, it is better to use low frequenct positional embedding:\n",
    "\n",
    "$$ M^{(0)}(p) = [\\sin(\\pi\\text{FC}([p-x^1_1, ..., p-x^{n_\\text{per}}_K])), \n",
    "        \\cos(\\pi\\text{FC}([p-x^1_1, ..., p-x^{n_\\text{per}}_K]))] $$\n",
    "\n",
    "After that all obtain results are put on the SPADE ResBlock which is proposed in this paper. SPADE takes two feature maps as input. First use BatchNorm to\n",
    "normalize input followed by two convolutions to map to the new mean and new standard deviation.\n",
    "\n",
    "$$ M^{(i)} = \\text{SPADE ResBlock} (M^{(i-1)}, W_\\text{mask})\\\\\n",
    "        M = \\text{softmax}(M^{(T_\\text{mask})}) $$\n",
    "        \n",
    "<div align=\"center\">\n",
    "<img src=\"./figures/level2.png\" width=\"700\"/>\n",
    "<figcaption>Strategy for Level 2</figcaption>\n",
    "</div>\n",
    "\n",
    "## Level 3: Mask-conditioned Image Generation\n",
    "In this level, foreground and the background are generated separately and blend them linearly by reusing the masks from the previous level. Embedding maps of both foreground and background are generated seperately:\n",
    "\n",
    "$$ W_\\text{fg}(p) = \\sum_{k=1}^K M_k(p) w_k. $$\n",
    "$$ W_\\text{bg} = \\text{MLP}_\\text{bg\\_app}(z_\\text{bg\\_app}). $$\n",
    "\n",
    "These wieghts are used to generate background and foreground:\n",
    "$$ F^{(i)} =  \\text{SPADE ResBlock} (F^{(i-1)}, W_\\text{fg}) $$\n",
    "$$ B^{(i)} = \\text{AdaIN ConvBlock}  (B^{(i-1)}, W_\\text{bg}) $$\n",
    "\n",
    "All obtained results are concataned to get final mask and result:\n",
    "$$ I = \\text{Conv}((1-M_\\text{bg})\\otimes F + M_\\text{bg}\\otimes B) $$\n",
    "\n",
    "<p>\n",
    "  <img src=\"./figures/foreground.png\" width=\"700\" />\n",
    "  <img src=\"./figures/background.png\" width=\"700\" /> \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import importlib\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dataset import CelebAWildTrain\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import os\n",
    "from model import Generator\n",
    "from other_models import Discriminator\n",
    "from tqdm import tqdm\n",
    "from evaluate import evaluate\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "All parameters are stored in object of Params:\n",
    "\n",
    "All important hyperparemeters such as learning rates are obtained from paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.latent_dim = 256\n",
    "        self.cluster_number = 8\n",
    "        self.n_per_kp = 4\n",
    "        self.batch_size = 16\n",
    "        self.lr_gen = 1e-4 \n",
    "        self.lr_disc = 4e-4 \n",
    "        self.num_workers = 0\n",
    "        self.data_root = ''\n",
    "        self.class_name = 'celeba_wild'\n",
    "        self.image_size = 128\n",
    "        self.embedding_dim = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "device = torch.device(device) if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Params()\n",
    "args.log = \"GanSEG\"\n",
    "\n",
    "os.makedirs(args.log, exist_ok=True)\n",
    "with open(os.path.join(args.log, 'parameters.json'), 'wt') as f:\n",
    "    json.dump(args.__dict__, f, indent=2)\n",
    "\n",
    "generator = Generator(args).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "optim_disc = torch.optim.Adam(discriminator.parameters(), lr=args.lr_disc, betas=(0.5, 0.9))\n",
    "optim_gen = torch.optim.Adam(filter(lambda p: p.requires_grad, generator.parameters()), lr=args.lr_gen, betas=(0.5, 0.9))\n",
    "\n",
    "generator = torch.nn.DataParallel(generator)\n",
    "discriminator = torch.nn.DataParallel(discriminator)\n",
    "\n",
    "checkpoint_dir = os.path.join(args.log, 'checkpoints')\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Architecture\n",
      "DataParallel(\n",
      "  (module): Generator(\n",
      "    (keypoints_embedding): Embedding(8, 128)\n",
      "    (mask_spade_blocks): ModuleList(\n",
      "      (0): SPADE(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std3): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean3): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv6): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): SPADE(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): SPADE(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): SPADE(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std2): Conv2d(128, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean2): Conv2d(128, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv4): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv6): Conv2d(128, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (spade_blocks): ModuleList(\n",
      "      (0): SPADE(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std3): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean3): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv6): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): SPADE(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv6): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): SPADE(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): SPADE(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_std2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv_mean2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (adain_blocks): ModuleList(\n",
      "      (0): AdaIN(\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (conv_std): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (conv_mean): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): AdaIN(\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (conv_std): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (conv_mean): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): AdaIN(\n",
      "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (conv_std): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (conv_mean): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): AdaIN(\n",
      "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (conv1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (conv_std): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (conv_mean): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (x_start): PositionalEmbedding(\n",
      "      (pe): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (mask_start): PositionalEmbedding(\n",
      "      (pe): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (bg_start): PositionalEmbedding(\n",
      "      (pe): Conv2d(2, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (rep_pad): ReplicationPad2d((10, 10, 10, 10))\n",
      "    (gen_keypoints_embedding_noise): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): LeakyReLU(negative_slope=0.2)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): LeakyReLU(negative_slope=0.2)\n",
      "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "    (gen_keypoints_layer): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): LeakyReLU(negative_slope=0.2)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): LeakyReLU(negative_slope=0.2)\n",
      "      (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2)\n",
      "      (8): Linear(in_features=256, out_features=64, bias=True)\n",
      "    )\n",
      "    (gen_background_embedding): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): LeakyReLU(negative_slope=0.2)\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): LeakyReLU(negative_slope=0.2)\n",
      "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Discriminator Architecture\n",
      "DataParallel(\n",
      "  (module): Discriminator(\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=32768, out_features=512, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Linear(in_features=512, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Generator Architecture\")\n",
    "print(generator)\n",
    "print(\"Discriminator Architecture\")\n",
    "print(discriminator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CelebAWildTrain(\"\", args.image_size)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                                       num_workers=args.num_workers, pin_memory=True, drop_last=True)\n",
    "test_input_batch = {'input_noise{}'.format(noise_i): torch.randn(args.batch_size, *noise_shape).to(device)\n",
    "                    for noise_i, noise_shape in enumerate(generator.module.noise_shapes)}\n",
    "test_input_batch['bg_trans'] = torch.rand(args.batch_size, 1, 2).to(device) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45609, 3, 128, 128])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(500):    \n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "    total_disc_loss = 0\n",
    "    total_gen_loss = 0\n",
    "    prog = tqdm(enumerate(data_loader))\n",
    "    for batch_index, batch in prog:\n",
    "        # update discriminator\n",
    "        optim_disc.zero_grad()\n",
    "        optim_gen.zero_grad()\n",
    "\n",
    "        batch = {'img': batch['img'].to(device)}\n",
    "        batch['img'].requires_grad_()\n",
    "        input_gen = {'input_noise{}'.format(noise_i): torch.randn(args.batch_size, *noise_shape).to(device)\n",
    "                    for noise_i, noise_shape in enumerate(generator.module.noise_shapes)}\n",
    "        input_gen['bg_trans'] = torch.rand(args.batch_size, 1, 2).to(device) * 2 - 1\n",
    "\n",
    "        fake_input = generator(input_gen)\n",
    "        real_disc = discriminator(batch)\n",
    "        fake_disc = discriminator(fake_input)\n",
    "        disc_loss = F.softplus(fake_disc).mean() + F.softplus(-real_disc).mean()\n",
    "        if batch_index % 4 == 0:\n",
    "            disc_loss = disc_loss + penalty(batch['img'], real_disc)\n",
    "        disc_loss.backward()\n",
    "        total_disc_loss += disc_loss.item()\n",
    "        optim_disc.step()\n",
    "\n",
    "        # update generator\n",
    "        optim_disc.zero_grad()\n",
    "        optim_gen.zero_grad()\n",
    "\n",
    "        input_gen = {'input_noise{}'.format(noise_i): torch.randn(args.batch_size, *noise_shape).to(device)\n",
    "                        for noise_i, noise_shape in enumerate(generator.module.noise_shapes)}\n",
    "        input_gen['bg_trans'] = torch.rand(args.batch_size, 1, 2).to(device) * 2 - 1\n",
    "        fake_input = generator(input_gen)\n",
    "        fake_disc = discriminator(fake_input)\n",
    "        gen_loss = F.softplus(-fake_disc).mean()\n",
    "        gen_loss.backward()\n",
    "        total_gen_loss += gen_loss.item()\n",
    "        optim_gen.step()\n",
    "        disc_loss, gen_loss = total_disc_loss / len(data_loader) / 2, total_gen_loss / len(data_loader)\n",
    "        if batch_index == 1000:\n",
    "            break\n",
    "        prog.set_description(f\"Epoch: {epoch + 1}, disc_loss:  {disc_loss}, gen_loss: {gen_loss}\")\n",
    "    evaluate(generator, test_input_gen, args, epoch)\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        torch.save({'generator': generator.module.state_dict(), 'discriminator': discriminator.module.state_dict(), 'optim_gen': optim_gen.state_dict(), 'optim_disc': optim_disc.state_dict(),},os.path.join(checkpoint_dir, 'epoch_{}.model'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, disc_loss:  0.91602554521552, gen_loss: 2.9154146088120627: : 1000it [17:04,  1.02s/it]  \n",
      "Epoch: 2, disc_loss:  0.19575286904447958, gen_loss: 1.3049921820260453: : 1000it [17:09,  1.03s/it]  \n",
      "Epoch: 3, disc_loss:  0.16392073070793822, gen_loss: 1.1133889933113466: : 1000it [17:23,  1.04s/it]  \n",
      "Epoch: 4, disc_loss:  0.1673950523660894, gen_loss: 1.0478422773302647: : 1000it [17:18,  1.04s/it]    \n",
      "Epoch: 5, disc_loss:  0.16378850753892932, gen_loss: 0.906951866683207: : 1000it [17:26,  1.05s/it]   \n",
      "Epoch: 6, disc_loss:  0.1642864903337077, gen_loss: 0.8528890935204139: : 1000it [17:25,  1.05s/it]   \n",
      "Epoch: 7, disc_loss:  0.15886002495100623, gen_loss: 0.7847563005016561: : 1000it [17:24,  1.04s/it]   \n",
      "Epoch: 8, disc_loss:  0.16731682119139454, gen_loss: 0.7638920359601055: : 1000it [17:26,  1.05s/it]   \n",
      "Epoch: 9, disc_loss:  0.1768046492233611, gen_loss: 0.7328230114464174: : 1000it [17:24,  1.04s/it]    \n",
      "Epoch: 10, disc_loss:  0.18231592197167246, gen_loss: 0.7279043149006994: : 1000it [17:23,  1.04s/it]   \n",
      "Epoch: 11, disc_loss:  0.246766946399421, gen_loss: 0.7160550303835618: : 1000it [17:22,  1.04s/it]     \n",
      "Epoch: 12, disc_loss:  0.20105214021707837, gen_loss: 0.6891262086337073: : 1000it [17:27,  1.05s/it]  \n",
      "Epoch: 13, disc_loss:  0.5057592329892673, gen_loss: 0.6789854133338259: : 1000it [17:26,  1.05s/it]    \n",
      "Epoch: 14, disc_loss:  0.21817433720617962, gen_loss: 0.6659025987721326: : 1000it [17:27,  1.05s/it]   \n",
      "Epoch: 15, disc_loss:  0.2704837605278743, gen_loss: 0.6581666157329291: : 1000it [17:30,  1.05s/it]    \n",
      "Epoch: 16, disc_loss:  0.2122004973470119, gen_loss: 0.6538607457541583: : 1000it [17:30,  1.05s/it]    \n",
      "Epoch: 17, disc_loss:  0.19493646167872244, gen_loss: 0.6362794649182705: : 1000it [17:27,  1.05s/it]   \n",
      "Epoch: 18, disc_loss:  0.24378937245983825, gen_loss: 0.6510043276506557: : 1000it [17:29,  1.05s/it]  \n",
      "Epoch: 19, disc_loss:  0.19404490737015742, gen_loss: 0.6428587244581758: : 1000it [17:36,  1.06s/it]   \n",
      "Epoch: 20, disc_loss:  0.18144089603633212, gen_loss: 0.6332077617080588: : 1000it [17:30,  1.05s/it]   \n",
      "Epoch: 21, disc_loss:  0.20403113204659076, gen_loss: 0.6409609125266995: : 1000it [17:28,  1.05s/it]  \n",
      "Epoch: 22, disc_loss:  0.20163132625190835, gen_loss: 0.645880325708473: : 1000it [17:29,  1.05s/it]    \n",
      "Epoch: 23, disc_loss:  0.19517553195618748, gen_loss: 0.6479485378662745: : 1000it [17:31,  1.05s/it]  \n",
      "Epoch: 24, disc_loss:  0.1884628846247991, gen_loss: 0.6344751320805466: : 1000it [17:32,  1.05s/it]    \n",
      "Epoch: 25, disc_loss:  0.18489027134682004, gen_loss: 0.6284861286219797: : 1000it [17:28,  1.05s/it]   \n",
      "Epoch: 26, disc_loss:  0.18329135458720358, gen_loss: 0.6338490488184125: : 1000it [17:27,  1.05s/it]    \n",
      "Epoch: 27, disc_loss:  0.17737608559298934, gen_loss: 0.6358133276931026: : 1000it [17:30,  1.05s/it]  \n",
      "Epoch: 28, disc_loss:  0.17247175581099694, gen_loss: 0.6248141477819075: : 1000it [17:32,  1.05s/it]   \n",
      "Epoch: 29, disc_loss:  0.18309974986210203, gen_loss: 0.6265653532063752: : 1000it [17:32,  1.05s/it]   \n",
      "Epoch: 30, disc_loss:  0.19481142593057532, gen_loss: 0.6276236511845338: : 1000it [17:33,  1.05s/it]   \n",
      "Epoch: 31, disc_loss:  0.18011580981706318, gen_loss: 0.6169128438804233: : 1000it [17:33,  1.05s/it]   \n",
      "Epoch: 32, disc_loss:  0.1887586452459034, gen_loss: 0.6249460739106463: : 1000it [17:29,  1.05s/it]   \n",
      "Epoch: 33, disc_loss:  0.17971346737522828, gen_loss: 0.6218632769689225: : 1000it [17:31,  1.05s/it]   \n",
      "Epoch: 34, disc_loss:  0.19088598083508643, gen_loss: 0.6408257004984638: : 1000it [17:29,  1.05s/it]   \n",
      "Epoch: 35, disc_loss:  0.1721425866976119, gen_loss: 0.6195369961596372: : 1000it [17:27,  1.05s/it]    \n",
      "Epoch: 36, disc_loss:  0.18127838198030205, gen_loss: 0.6163180573519907: : 1000it [17:30,  1.05s/it]   \n",
      "Epoch: 37, disc_loss:  0.19388023901403997, gen_loss: 0.621880965384475: : 1000it [17:29,  1.05s/it]    \n",
      "Epoch: 38, disc_loss:  0.17794316802108498, gen_loss: 0.6253662479446646: : 1000it [17:25,  1.05s/it]   \n",
      "Epoch: 39, disc_loss:  0.18326451484048575, gen_loss: 0.6142191594316249: : 1000it [17:27,  1.05s/it]  \n",
      "Epoch: 40, disc_loss:  0.22463075828656814, gen_loss: 0.6140654158932075: : 1000it [17:28,  1.05s/it]   \n",
      "Epoch: 41, disc_loss:  0.20923719453707076, gen_loss: 0.6165765097737312: : 1000it [17:32,  1.05s/it]   \n",
      "Epoch: 42, disc_loss:  0.2754581312390796, gen_loss: 0.6248016891772287: : 1000it [17:28,  1.05s/it]    \n",
      "Epoch: 43, disc_loss:  0.21539401654088705, gen_loss: 0.6123160480720955: : 1000it [17:26,  1.05s/it]  \n",
      "Epoch: 44, disc_loss:  0.19884948955293288, gen_loss: 0.6045724131245362: : 1000it [17:27,  1.05s/it]  \n",
      "Epoch: 45, disc_loss:  0.19975812158040834, gen_loss: 0.594257944205351: : 1000it [17:25,  1.05s/it]   \n",
      "Epoch: 46, disc_loss:  0.18140019585166062, gen_loss: 0.6024304033162301: : 1000it [17:29,  1.05s/it]   \n",
      "Epoch: 47, disc_loss:  0.20090101981372163, gen_loss: 0.6058241386685455: : 1000it [17:23,  1.04s/it]   \n",
      "Epoch: 48, disc_loss:  0.18631611475296186, gen_loss: 0.6001833874091768: : 1000it [17:24,  1.04s/it]   \n",
      "Epoch: 49, disc_loss:  0.19927488619821113, gen_loss: 0.6048985071271135: : 1000it [17:24,  1.04s/it]   \n",
      "Epoch: 50, disc_loss:  0.18598626392975187, gen_loss: 0.5848008295004828: : 1000it [17:22,  1.04s/it]   \n",
      "Epoch: 51, disc_loss:  0.20315842558417405, gen_loss: 0.5906121135803691: : 1000it [17:23,  1.04s/it]   \n",
      "Epoch: 52, disc_loss:  0.188537053978234, gen_loss: 0.5852501723745412: : 1000it [17:26,  1.05s/it]    \n",
      "Epoch: 53, disc_loss:  0.17863046951984105, gen_loss: 0.5866092727058813: : 1000it [17:24,  1.04s/it]   \n",
      "Epoch: 54, disc_loss:  0.19734356729084984, gen_loss: 0.5894373731864126: : 1000it [17:23,  1.04s/it]   \n",
      "Epoch: 55, disc_loss:  0.17773198360936684, gen_loss: 0.5911520260415579: : 1000it [17:22,  1.04s/it]   \n",
      "Epoch: 56, disc_loss:  0.19258893831780083, gen_loss: 0.5913273196053087: : 1000it [17:20,  1.04s/it]   \n",
      "Epoch: 57, disc_loss:  0.21025675797148755, gen_loss: 0.5939666920194501: : 1000it [17:22,  1.04s/it]   \n",
      "Epoch: 58, disc_loss:  0.18415104925632478, gen_loss: 0.5952652306724013: : 1000it [17:22,  1.04s/it]   \n",
      "Epoch: 59, disc_loss:  0.18585375975098525, gen_loss: 0.5947856491594984: : 1000it [17:13,  1.03s/it]   \n",
      "Epoch: 60, disc_loss:  0.19858397866550245, gen_loss: 0.5889847195985024: : 1000it [17:14,  1.03s/it]  \n",
      "Epoch: 61, disc_loss:  0.1901694577461795, gen_loss: 0.5835104177709212: : 1000it [17:14,  1.03s/it]   \n",
      "Epoch: 62, disc_loss:  0.18179702265220776, gen_loss: 0.5919914445385598: : 1000it [17:15,  1.04s/it]   \n",
      "Epoch: 63, disc_loss:  0.19271818788428055, gen_loss: 0.5877188001965221: : 1000it [17:15,  1.04s/it]  \n",
      "Epoch: 64, disc_loss:  0.19376798783477983, gen_loss: 0.5841155511454532: : 1000it [17:13,  1.03s/it]   \n",
      "Epoch: 65, disc_loss:  0.18385463028623347, gen_loss: 0.5927274364965004: : 1000it [17:14,  1.03s/it]  \n",
      "Epoch: 66, disc_loss:  0.18512612431718592, gen_loss: 0.5863211392101488: : 1000it [17:16,  1.04s/it]   \n",
      "Epoch: 67, disc_loss:  0.181657343747323, gen_loss: 0.5877389546026264: : 1000it [17:15,  1.04s/it]     \n",
      "Epoch: 68, disc_loss:  0.1833034806450208, gen_loss: 0.5831699748415696: : 1000it [17:14,  1.03s/it]    \n",
      "Epoch: 69, disc_loss:  0.175602811323969, gen_loss: 0.5773545826108832: : 1000it [17:13,  1.03s/it]     \n",
      "Epoch: 70, disc_loss:  0.18204531086118597, gen_loss: 0.5872873845225887: : 1000it [17:15,  1.04s/it]  \n",
      "Epoch: 71, disc_loss:  0.18227415494751512, gen_loss: 0.5896116223042471: : 1000it [17:15,  1.04s/it]   \n",
      "Epoch: 72, disc_loss:  0.1787215944444924, gen_loss: 0.5927801659232692: : 1000it [17:13,  1.03s/it]    \n",
      "Epoch: 73, disc_loss:  0.18703432195542152, gen_loss: 0.5964238235197569: : 1000it [17:14,  1.03s/it]   \n",
      "Epoch: 74, disc_loss:  0.18638764174360978, gen_loss: 0.5958929153074298: : 1000it [17:16,  1.04s/it]   \n",
      "Epoch: 75, disc_loss:  0.18303909441881014, gen_loss: 0.5875328643489303: : 1000it [17:17,  1.04s/it]  \n",
      "Epoch: 76, disc_loss:  0.1761319915662732, gen_loss: 0.5864270337631828: : 1000it [17:18,  1.04s/it]    \n",
      "Epoch: 77, disc_loss:  0.17915553805075193, gen_loss: 0.5919208042349732: : 1000it [17:18,  1.04s/it]   \n",
      "Epoch: 78, disc_loss:  0.18306565303028677, gen_loss: 0.5863341155752801: : 1000it [17:15,  1.04s/it]   \n",
      "Epoch: 79, disc_loss:  0.187178556547876, gen_loss: 0.5912692704117088: : 1000it [17:15,  1.04s/it]     \n",
      "Epoch: 80, disc_loss:  0.19667043371158735, gen_loss: 0.5832987457722948: : 1000it [17:16,  1.04s/it]   \n",
      "Epoch: 81, disc_loss:  0.17982480583483712, gen_loss: 0.5864208078593538: : 1000it [17:16,  1.04s/it]   \n",
      "Epoch: 82, disc_loss:  0.17940220181879243, gen_loss: 0.5750609795252483: : 1000it [17:16,  1.04s/it]   \n",
      "Epoch: 83, disc_loss:  0.1847999776925957, gen_loss: 0.581591270942437: : 1000it [17:21,  1.04s/it]     \n",
      "Epoch: 84, disc_loss:  0.19507499656133484, gen_loss: 0.5883473753563144: : 1000it [17:19,  1.04s/it]   \n",
      "Epoch: 85, disc_loss:  0.18678577586224204, gen_loss: 0.5814169064111877: : 1000it [17:23,  1.04s/it]  \n"
     ]
    }
   ],
   "source": [
    "with open(\"logs.txt\") as f:\n",
    "    lines = f.read()\n",
    "    print(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "images = []\n",
    "images_seg = []\n",
    "filenames = [filename for filename in os.listdir(\"./GanSEG/results/\") if \"seg\" not in filename]\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(os.path.join(\"./GanSEG/results/\", filename)))\n",
    "imageio.mimsave('./GanSEG/gan.gif', images, duration= 0.5)\n",
    "filenames_seg = [filename for filename in os.listdir(\"./GanSEG/results/\") if \"seg\" in filename]\n",
    "for filename in filenames_seg:\n",
    "    images_seg.append(imageio.imread(os.path.join(\"./GanSEG/results/\", filename)))\n",
    "imageio.mimsave('./GanSEG/gan_seg.gif', images_seg, duration= 0.5)\n",
    "img = Image.open(\"./GanSEG/gan.gif\").convert('RGB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"./GanSEG/gan.gif\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_load = Params()\n",
    "\n",
    "generator = Generator(args).to(device)\n",
    "gen_checkpoint = torch.load(\"./best_model.model\",\n",
    "                            map_location=lambda storage, location: storage)\n",
    "generator.load_state_dict(gen_checkpoint['generator'])\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_input = {'input_noise{}'.format(noise_i): torch.randn(args.batch_size, *noise_shape).to(device)\n",
    "                    for noise_i, noise_shape in enumerate(generator.noise_shapes)}\n",
    "loaded_input['bg_trans'] = torch.rand(args.batch_size, 1, 2).to(device) * 2 - 1\n",
    "\n",
    "evaluate(generator, loaded_input, args, \"test\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./GanSEG/results/test.png\" align=\"left\"/><img src=\"./GanSEG/results/test_segmaps.png\" align=\"left\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challanges Faced\n",
    "### Model Architecture\n",
    "\n",
    "GANSeg model architecture basically consists of 2 different module: Generator and Discriminator. Discriminator is basically fully connected layer and it could be implemented according to what paper suggests. However, Generator module requires different submodules which is not explained in detail. SPADE and AdaIN sub modules can be given as example. Therefore, some assumptions were made by implementing this module. Also implementing forward function of the Generator module was pretty overwhelming because 3 important level which is explained in above were need to be implemented in here. Especially, \"Level 2: From Points to Masks\" part could not be impelemented properly because equations that paper suggests seem incomplete in terms of the matrix dimensions. In order to match matrix dimensions, some transpose operations were done. However, it is possible that these changes lead to some performance drops. Finally, \n",
    "\n",
    "### Gradient Penalty\n",
    "Gradient penalty is suggested in the different locations in the paper. Math part is the penalty seems incomplete in the paper and therefore, gradient penalty part could not be implemented in v2. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "difseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
